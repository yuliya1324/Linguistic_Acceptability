# Linguistic_Acceptability

Проект выполнили: *Юлия Короткова* и *Яков Раскинд*

**Цель**: Выяснить, что предобученные языковые модели знают о лингвистической приемлемости

## Методы

Для ответа на этот вопрос мы использовали разные методы пробинга для энкодерных и декодерных моделей: анализ attention и zero-shot learning

### Анализ attention

### Zero-shot learning

Оценивались модели обученные на NLI или multi-tasking, где NLI тоже присутствовал. Для этого задача приемлемости формулировалась как NLI.

Также оценивались генеративные модели с передачей примера в промпт и без.

## Данные

В качестве данных для пробинга мы взяли датасет [CoLA](https://nyu-mll.github.io/CoLA/). В нем есть разметка каждого предложения на приемлемость (1 - приемлемое, 0 - неприемлемое). Для анализа attention были отобраны пары предложений, в которых есть минимальные различия, чтобы сравнить attention к различающейся части. Для zero-shot learning использовался весь датасет.
