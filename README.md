# Linguistic_Acceptability

Проект выполнили: *Юлия Короткова* и *Яков Раскинд*

**Цель**: Выяснить, что предобученные языковые модели знают о лингвистической приемлемости

## Методы

Для ответа на этот вопрос мы использовали разные методы пробинга для энкодерных и декодерных моделей: анализ attention и zero-shot learning

### Анализ attention

Брались пары предложений с минимальными различиями, и анализировалась та часть, которая различается.

### Zero-shot learning

Оценивались модели обученные на NLI или multi-tasking, где NLI тоже присутствовал. Для этого задача приемлемости формулировалась как NLI.

Также оценивались генеративные модели с передачей примера в промпт и без.

## Данные

В качестве данных для пробинга мы взяли датасет [CoLA](https://nyu-mll.github.io/CoLA/). В нем есть разметка каждого предложения на приемлемость (1 - приемлемое, 0 - неприемлемое).
